{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b48f40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import add, Input, Dense, Conv2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D, Dropout, Flatten, Concatenate, Reshape, Activation, BatchNormalization, GlobalAveragePooling2D, ZeroPadding2D\n",
    "from tensorflow.nn import local_response_normalization\n",
    "from tensorflow.python.keras.layers.merge import concatenate\n",
    "from tensorflow.keras.activations import relu\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import matplotlib\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.regularizers import l2, l1, l1_l2\n",
    "from itertools import permutations, combinations\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b165a215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: GeForce RTX 3080, pci bus id: 0000:41:00.0, compute capability: 8.6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.60\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "tf.compat.v1.keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b49c953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 50000 images belonging to 10 classes.\n",
      "Found 5000 images belonging to 10 classes.\n",
      "Found 5000 images belonging to 10 classes.\n",
      "data batch shape: (32, 299, 299, 3)\n",
      "labels batch shape: (32, 10)\n"
     ]
    }
   ],
   "source": [
    "#### Using CIFAR10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Preprocess the data (these are NumPy arrays)\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "\n",
    "\n",
    "y_train = y_train.astype(\"float32\")\n",
    "y_test = y_test.astype(\"float32\")\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes=10) \n",
    "\n",
    "global_batch_size = 32\n",
    "image_resize = 299\n",
    "\n",
    "########## Train\n",
    "#### removing data augmentation only here for profiling\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# train_datagen = ImageDataGenerator(rescale=1./255, featurewise_center = True,\n",
    "#                                    rotation_range = 20, horizontal_flip = True, height_shift_range = 0.2,\n",
    "#                                    width_shift_range = 0.2, zoom_range = 0.2, channel_shift_range = 0.2)\n",
    "\n",
    "\n",
    "train_it = train_datagen.flow_from_directory(\n",
    "        'cifar10/train',\n",
    "        class_mode='categorical',\n",
    "        target_size=(image_resize, image_resize),\n",
    "        batch_size=global_batch_size)\n",
    "\n",
    "\n",
    "############ Test\n",
    "test_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.5)\n",
    "\n",
    "validation_it = test_datagen.flow_from_directory(\n",
    "        'cifar10/test',\n",
    "        class_mode='categorical',\n",
    "        target_size=(image_resize, image_resize),\n",
    "        batch_size=global_batch_size,\n",
    "        subset = \"training\",seed = 545)\n",
    "\n",
    "test_it = test_datagen.flow_from_directory(\n",
    "        'cifar10/test',\n",
    "        class_mode='categorical',\n",
    "        target_size=(image_resize, image_resize),\n",
    "        batch_size=global_batch_size,\n",
    "        subset = \"validation\",\n",
    "        seed = 545)\n",
    "\n",
    "\n",
    "for data_batch, labels_batch in train_it:\n",
    "    print('data batch shape:', data_batch.shape)\n",
    "    print('labels batch shape:', labels_batch.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d1dff01",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLoss(keras.losses.Loss):\n",
    "    def __init__(self, factor):\n",
    "        super().__init__()\n",
    "        self.factor = factor\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        ce = tf.keras.losses.categorical_crossentropy(y_true, y_pred)\n",
    "        return ce * self.factor\n",
    "    \n",
    " \n",
    "\n",
    "class conv2d_bn(tf.keras.layers.Layer):\n",
    "    def __init__(self, filters, num_row, num_col, padding='same',strides=(1, 1)):\n",
    "        super(conv2d_bn, self).__init__()\n",
    "        \n",
    "        self.conv = Conv2D(filters, (num_row, num_col), strides=strides, padding=padding, use_bias=False)\n",
    "        self.bn = BatchNormalization(axis=3, scale=False)\n",
    "        self.act = Activation('relu')\n",
    "        \n",
    "    def call(self, x, training):\n",
    "        if (training != False and training != True):\n",
    "            training = False\n",
    "\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x, training = training)\n",
    "        x = self.act(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    \n",
    "\n",
    "class CIFAR_Inception_V3(tf.keras.Model):\n",
    "    def __init__(self, branch_number):\n",
    "        super(CIFAR_Inception_V3, self).__init__()\n",
    "\n",
    "        self.branch_number = branch_number\n",
    "\n",
    "        \n",
    "        ### Begining layers\n",
    "        self.conv1_bg = Conv2D(32, (3, 3), strides=(2,2) , padding='valid', use_bias=False, input_shape=(image_resize, image_resize, 3))\n",
    "        self.bn1_bg = BatchNormalization(axis=3, scale=False)\n",
    "        \n",
    "        \n",
    "        self.conv2_bg = conv2d_bn(32, 3, 3, padding='valid')\n",
    "        self.conv3_bg = conv2d_bn(64, 3, 3)\n",
    "        self.pool1_bg = MaxPooling2D((3, 3), strides=(2, 2))\n",
    "\n",
    "        self.conv4_bg = conv2d_bn(80, 1, 1, padding='valid')\n",
    "        self.conv5_bg = conv2d_bn(192, 3, 3, padding='valid')\n",
    "        self.pool2_bg = MaxPooling2D((3, 3), strides=(2, 2))\n",
    "\n",
    "        \n",
    "        ### Inception blocks\n",
    "        # mixed 0: 35 x 35 x 256 (bl0)\n",
    "        self.branch1x1_bl0 = conv2d_bn(64, 1, 1)\n",
    "\n",
    "        self.branch5x5_bl0_0 = conv2d_bn(48, 1, 1)\n",
    "        self.branch5x5_bl0_1 = conv2d_bn(64, 5, 5)\n",
    "\n",
    "        self.branch3x3dbl_bl0_0 = conv2d_bn(64, 1, 1)\n",
    "        self.branch3x3dbl_bl0_1 = conv2d_bn(96, 3, 3)\n",
    "        self.branch3x3dbl_bl0_2 = conv2d_bn(96, 3, 3)\n",
    "        \n",
    "        self.branch_pool_bl0 = AveragePooling2D((3, 3), strides=(1, 1), padding='same')\n",
    "        self.branch_poolout_bl0 = conv2d_bn(32, 1, 1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # mixed 1: 35 x 35 x 288 (bl1)\n",
    "        self.branch1x1_bl1 = conv2d_bn(64, 1, 1)\n",
    "\n",
    "        self.branch5x5_bl1_0 = conv2d_bn(48, 1, 1)\n",
    "        self.branch5x5_bl1_1 = conv2d_bn(64, 5, 5)\n",
    "\n",
    "        self.branch3x3dbl_bl1_0 = conv2d_bn(64, 1, 1)\n",
    "        self.branch3x3dbl_bl1_1 = conv2d_bn(96, 3, 3)\n",
    "        self.branch3x3dbl_bl1_2 = conv2d_bn(96, 3, 3)\n",
    "\n",
    "        self.branch_pool_bl1 = AveragePooling2D((3, 3), strides=(1, 1), padding='same')\n",
    "        self.branch_poolout_bl1 = conv2d_bn(64, 1, 1)\n",
    "        \n",
    "\n",
    "        # mixed 2: 35 x 35 x 288 (bl2)\n",
    "        self.branch1x1_bl2 = conv2d_bn(64, 1, 1)\n",
    "\n",
    "        self.branch5x5_bl2_0 = conv2d_bn(48, 1, 1)\n",
    "        self.branch5x5_bl2_1 = conv2d_bn(64, 5, 5)\n",
    "\n",
    "        self.branch3x3dbl_bl2_0 = conv2d_bn(64, 1, 1)\n",
    "        self.branch3x3dbl_bl2_1 = conv2d_bn(96, 3, 3)\n",
    "        self.branch3x3dbl_bl2_2 = conv2d_bn(96, 3, 3)\n",
    "\n",
    "        self.branch_pool_bl2 = AveragePooling2D((3, 3), strides=(1, 1), padding='same')\n",
    "        self.branch_poolout_bl2 = conv2d_bn(64, 1, 1)\n",
    "        \n",
    "        \n",
    "\n",
    "        # mixed 3: 17 x 17 x 768 (bl3)\n",
    "        self.branch3x3_bl3 = conv2d_bn(384, 3, 3, strides=(2, 2), padding='valid')\n",
    "\n",
    "        self.branch3x3dbl_bl3_0 = conv2d_bn(64, 1, 1)\n",
    "        self.branch3x3dbl_bl3_1 = conv2d_bn(96, 3, 3)\n",
    "        self.branch3x3dbl_bl3_2 = conv2d_bn(96, 3, 3, strides=(2, 2), padding='valid')\n",
    "\n",
    "        self.branch_pool_bl3 = MaxPooling2D((3, 3), strides=(2, 2))\n",
    "\n",
    "        # mixed 4: 17 x 17 x 768 (bl4)\n",
    "        self.branch1x1_bl4 = conv2d_bn(192, 1, 1)\n",
    "\n",
    "        self.branch7x7_bl4_0 = conv2d_bn(128, 1, 1)\n",
    "        self.branch7x7_bl4_1 = conv2d_bn(128, 1, 7)\n",
    "        self.branch7x7_bl4_2 = conv2d_bn(192, 7, 1)\n",
    "\n",
    "        self.branch7x7dbl_bl4_0 = conv2d_bn(128, 1, 1)\n",
    "        self.branch7x7dbl_bl4_1 = conv2d_bn(128, 7, 1)\n",
    "        self.branch7x7dbl_bl4_2 = conv2d_bn(128, 1, 7)\n",
    "        self.branch7x7dbl_bl4_3 = conv2d_bn(128, 7, 1)\n",
    "        self.branch7x7dbl_bl4_4 = conv2d_bn(192, 1, 7)\n",
    "\n",
    "        self.branch_pool_bl4 = AveragePooling2D((3, 3), strides=(1, 1), padding='same')\n",
    "        self.branch_poolou4_bl4 = conv2d_bn(192, 1, 1)\n",
    "        \n",
    "    \n",
    "        # mixed 5: 17 x 17 x 768 (bl5)\n",
    "        self.branch1x1_bl5 = conv2d_bn(192, 1, 1)\n",
    "\n",
    "        self.branch7x7_bl5_0 = conv2d_bn(160, 1, 1)\n",
    "        self.branch7x7_bl5_1 = conv2d_bn(160, 1, 7)\n",
    "        self.branch7x7_bl5_2 = conv2d_bn(192, 7, 1)\n",
    "\n",
    "        self.branch7x7dbl_bl5_0 = conv2d_bn(160, 1, 1)\n",
    "        self.branch7x7dbl_bl5_1 = conv2d_bn(160, 7, 1)\n",
    "        self.branch7x7dbl_bl5_2 = conv2d_bn(160, 1, 7)\n",
    "        self.branch7x7dbl_bl5_3 = conv2d_bn(160, 7, 1)\n",
    "        self.branch7x7dbl_bl5_4 = conv2d_bn(192, 1, 7)\n",
    "\n",
    "        self.branch_pool_bl5 = AveragePooling2D((3, 3), strides=(1, 1), padding='same')\n",
    "        self.branch_poolout_bl5 = conv2d_bn(192, 1, 1)\n",
    "        \n",
    "        \n",
    "        # mixed 6: 17 x 17 x 768 (bl6)\n",
    "        self.branch1x1_bl6 = conv2d_bn(192, 1, 1)\n",
    "\n",
    "        self.branch7x7_bl6_0 = conv2d_bn(160, 1, 1)\n",
    "        self.branch7x7_bl6_1 = conv2d_bn(160, 1, 7)\n",
    "        self.branch7x7_bl6_2 = conv2d_bn(192, 7, 1)\n",
    "\n",
    "        self.branch7x7dbl_bl6_0 = conv2d_bn(160, 1, 1)\n",
    "        self.branch7x7dbl_bl6_1 = conv2d_bn(160, 7, 1)\n",
    "        self.branch7x7dbl_bl6_2 = conv2d_bn(160, 1, 7)\n",
    "        self.branch7x7dbl_bl6_3 = conv2d_bn(160, 7, 1)\n",
    "        self.branch7x7dbl_bl6_4 = conv2d_bn(192, 1, 7)\n",
    "\n",
    "        self.branch_pool_bl6 = AveragePooling2D((3, 3), strides=(1, 1), padding='same')\n",
    "        self.branch_poolout_bl6 = conv2d_bn(192, 1, 1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        # mixed 7: 17 x 17 x 768 (bl7)\n",
    "        self.branch1x1_bl7 = conv2d_bn(192, 1, 1)\n",
    "\n",
    "        self.branch7x7_bl7_0 = conv2d_bn(192, 1, 1)\n",
    "        self.branch7x7_bl7_1 = conv2d_bn(192, 1, 7)\n",
    "        self.branch7x7_bl7_2 = conv2d_bn(192, 7, 1)\n",
    "\n",
    "        self.branch7x7dbl_bl7_0 = conv2d_bn(192, 1, 1)\n",
    "        self.branch7x7dbl_bl7_1 = conv2d_bn(192, 7, 1)\n",
    "        self.branch7x7dbl_bl7_2 = conv2d_bn(192, 1, 7)\n",
    "        self.branch7x7dbl_bl7_3 = conv2d_bn(192, 7, 1)\n",
    "        self.branch7x7dbl_bl7_4 = conv2d_bn(192, 1, 7)\n",
    "\n",
    "        self.branch_pool_bl7 = AveragePooling2D((3, 3), strides=(1, 1), padding='same')\n",
    "        self.branch_poolout_bl7 = conv2d_bn(192, 1, 1)\n",
    "        \n",
    "\n",
    "        # mixed 8: 8 x 8 x 1280 (bl8)\n",
    "        self.branch3x3_bl8 = conv2d_bn(192, 1, 1)\n",
    "        self.branch3x3_bl8_0 = conv2d_bn(320, 3, 3, strides=(2, 2), padding='valid')\n",
    "\n",
    "        self.branch7x7x3_bl8_0 = conv2d_bn(192, 1, 1)\n",
    "        self.branch7x7x3_bl8_1 = conv2d_bn(192, 1, 7)\n",
    "        self.branch7x7x3_bl8_2 = conv2d_bn(192, 7, 1)\n",
    "        self.branch7x7x3_bl8_3 = conv2d_bn(192, 3, 3, strides=(2, 2), padding='valid')\n",
    "        \n",
    "        self.branch_pool_bl8 = MaxPooling2D((3, 3), strides=(2, 2))\n",
    "\n",
    "        # mixed 9: 8 x 8 x 2048 (bl9)\n",
    "        self.branch1x1_bl9 = conv2d_bn(320, 1, 1)\n",
    "\n",
    "        self.branch3x3_bl9 = conv2d_bn(384, 1, 1)\n",
    "        self.branch3x3_1_bl9 = conv2d_bn(384, 1, 3)\n",
    "        self.branch3x3_2_bl9 = conv2d_bn(384, 3, 1)\n",
    "\n",
    "        self.branch3x3dbl_bl9 = conv2d_bn(448, 1, 1)\n",
    "        self.branch3x3dbl_bl9_0 = conv2d_bn(384, 3, 3)\n",
    "        self.branch3x3dbl_1_bl9 = conv2d_bn(384, 1, 3)\n",
    "        self.branch3x3dbl_2_bl9 = conv2d_bn(384, 3, 1)\n",
    "\n",
    "        self.branch_pool_bl9 = AveragePooling2D((3, 3), strides=(1, 1), padding='same')\n",
    "        self.branch_poolout_bl9 = conv2d_bn(192, 1, 1)\n",
    "        \n",
    "\n",
    "        # mixed 10: 8 x 8 x 2048 (bl10)\n",
    "        self.branch1x1_bl10 = conv2d_bn(320, 1, 1)\n",
    "\n",
    "        self.branch3x3_bl10 = conv2d_bn(384, 1, 1)\n",
    "        self.branch3x3_1_bl10 = conv2d_bn(384, 1, 3)\n",
    "        self.branch3x3_2_bl10 = conv2d_bn(384, 3, 1)\n",
    "\n",
    "        self.branch3x3dbl_bl10_0 = conv2d_bn(448, 1, 1)\n",
    "        self.branch3x3dbl_bl10_1 = conv2d_bn(384, 3, 3)\n",
    "        self.branch3x3dbl_1_bl10 = conv2d_bn(384, 1, 3)\n",
    "        self.branch3x3dbl_2_bl10 = conv2d_bn(384, 3, 1)\n",
    "\n",
    "        self.branch_pool_bl10 = AveragePooling2D((3, 3), strides=(1, 1), padding='same')\n",
    "        self.branch_poolout_bl10 = conv2d_bn(192, 1, 1)\n",
    "        \n",
    "        \n",
    "\n",
    "        \n",
    "        ### last exit branch\n",
    "        self.global_pool = GlobalAveragePooling2D()\n",
    "        self.dense_0 = Dense(10, activation='softmax')\n",
    "        self.dense_1 = Dense(10, activation='softmax')\n",
    "        self.dense_2 = Dense(10, activation='softmax')\n",
    "        self.dense_3 = Dense(10, activation='softmax')\n",
    "        self.dense_4 = Dense(10, activation='softmax')\n",
    "        self.dense_5 = Dense(10, activation='softmax')\n",
    "        self.dense_6 = Dense(10, activation='softmax')\n",
    "        self.dense_7 = Dense(10, activation='softmax')\n",
    "        self.dense_8 = Dense(10, activation='softmax')\n",
    "        self.dense_9 = Dense(10, activation='softmax')\n",
    "        self.dense_10 = Dense(10, activation='softmax')\n",
    "        self.dense_11 = Dense(10, activation='softmax')\n",
    "        \n",
    "        self.dense_last = Dense(10, activation='softmax')\n",
    "        \n",
    "        \n",
    "        \n",
    "    def call(self, inputs, training):\n",
    "        inference_flag = -1000\n",
    "        channel_axis = 3\n",
    "        comp_latency_list_backbone = [0 for i in range(self.branch_number)]\n",
    "        comp_latency_list_exitbranch = [0 for i in range(self.branch_number)]\n",
    "        out_vector_list = [[] for i in range(self.branch_number)]\n",
    "        \n",
    "        if (training != False and training != True):\n",
    "            inference_flag = 1000\n",
    "            training = False\n",
    "            \n",
    "        ################ HERE ########################\n",
    "        ### begining layers\n",
    "        start_time = tf.timestamp()\n",
    "        x = self.conv1_bg(inputs)\n",
    "        x = self.bn1_bg(x, training = training)\n",
    "        x = relu(x)\n",
    "\n",
    "        x = self.conv2_bg(x)\n",
    "        x = self.conv3_bg(x)\n",
    "        x = self.pool1_bg(x)\n",
    "        comp_latency_list_backbone[0] = tf.timestamp() - start_time\n",
    "        \n",
    "#         print(\"branch 0 \", x.shape)\n",
    "        ### *** exit branch 0\n",
    "        start_time = tf.timestamp()\n",
    "        temp = self.global_pool(x)\n",
    "        temp = self.dense_0(temp)\n",
    "        out_vector_list[0] = temp\n",
    "        comp_latency_list_exitbranch[0] = tf.timestamp() - start_time\n",
    "        \n",
    "        \n",
    "        \n",
    "        start_time = tf.timestamp()\n",
    "        x = self.conv4_bg(x)\n",
    "        x = self.conv5_bg(x)\n",
    "        x = self.pool2_bg(x)\n",
    "        comp_latency_list_backbone[1] = tf.timestamp() - start_time\n",
    "        \n",
    "#         print(\"branch 1 \", x.shape)\n",
    "        ### *** exit branch 1\n",
    "        start_time = tf.timestamp()\n",
    "        temp = self.global_pool(x)\n",
    "        temp = self.dense_1(temp)\n",
    "        out_vector_list[1] = temp\n",
    "        comp_latency_list_exitbranch[1] = tf.timestamp() - start_time\n",
    "\n",
    "        ### inception blocks\n",
    "        # mixed 0: 35 x 35 x 256 (bl0)\n",
    "        start_time = tf.timestamp()\n",
    "        branch1x1 = self.branch1x1_bl0(x)\n",
    "\n",
    "        branch5x5 = self.branch5x5_bl0_0(x)\n",
    "        branch5x5 = self.branch5x5_bl0_1(branch5x5)\n",
    "\n",
    "        branch3x3dbl = self.branch3x3dbl_bl0_0(x)\n",
    "        branch3x3dbl = self.branch3x3dbl_bl0_1(branch3x3dbl)\n",
    "        branch3x3dbl = self.branch3x3dbl_bl0_2(branch3x3dbl)\n",
    "\n",
    "        branch_pool = self.branch_pool_bl0(x)\n",
    "        branch_pool = self.branch_poolout_bl0(branch_pool)\n",
    "        x = concatenate([branch1x1, branch5x5, branch3x3dbl, branch_pool], axis=channel_axis)\n",
    "        comp_latency_list_backbone[2] = tf.timestamp() - start_time\n",
    "        \n",
    "#         print(\"branch 2 \", x.shape)\n",
    "        ### *** exit branch 2\n",
    "        start_time = tf.timestamp()\n",
    "        temp = self.global_pool(x)\n",
    "        temp = self.dense_2(temp)\n",
    "        out_vector_list[2] = temp\n",
    "        comp_latency_list_exitbranch[2] = tf.timestamp() - start_time\n",
    "        \n",
    "        # mixed 1: 35 x 35 x 288 (bl1)\n",
    "        start_time = tf.timestamp()\n",
    "        branch1x1 = self.branch1x1_bl1(x)\n",
    "\n",
    "        branch5x5 = self.branch5x5_bl1_0(x)\n",
    "        branch5x5 = self.branch5x5_bl1_1(branch5x5)\n",
    "\n",
    "        branch3x3dbl = self.branch3x3dbl_bl1_0(x)\n",
    "        branch3x3dbl = self.branch3x3dbl_bl1_1(branch3x3dbl)\n",
    "        branch3x3dbl = self.branch3x3dbl_bl1_2(branch3x3dbl)\n",
    "\n",
    "        branch_pool = self.branch_pool_bl1(x)\n",
    "        branch_pool = self.branch_poolout_bl1(branch_pool)\n",
    "        x = concatenate([branch1x1, branch5x5, branch3x3dbl, branch_pool], axis=channel_axis)\n",
    "        comp_latency_list_backbone[3] = tf.timestamp() - start_time\n",
    "        \n",
    "        \n",
    "#         print(\"branch 3 \", x.shape)\n",
    "        ### *** exit branch 3\n",
    "        start_time = tf.timestamp()\n",
    "        temp = self.global_pool(x)\n",
    "        temp = self.dense_3(temp)\n",
    "        out_vector_list[3] = temp\n",
    "        comp_latency_list_exitbranch[3] = tf.timestamp() - start_time\n",
    "        \n",
    "\n",
    "        # mixed 2: 35 x 35 x 288 (bl2)\n",
    "        start_time = tf.timestamp()\n",
    "        branch1x1 = self.branch1x1_bl2(x)\n",
    "\n",
    "        branch5x5 = self.branch5x5_bl2_0(x)\n",
    "        branch5x5 = self.branch5x5_bl2_1(branch5x5)\n",
    "\n",
    "        branch3x3dbl = self.branch3x3dbl_bl2_0(x)\n",
    "        branch3x3dbl = self.branch3x3dbl_bl2_1(branch3x3dbl)\n",
    "        branch3x3dbl = self.branch3x3dbl_bl2_2(branch3x3dbl)\n",
    "\n",
    "        branch_pool = self.branch_pool_bl2(x)\n",
    "        branch_pool = self.branch_poolout_bl2(branch_pool)\n",
    "        x = concatenate([branch1x1, branch5x5, branch3x3dbl, branch_pool], axis=channel_axis)\n",
    "        comp_latency_list_backbone[4] = tf.timestamp() - start_time\n",
    "        \n",
    "\n",
    "#         print(\"branch 4 \", x.shape)\n",
    "        ### *** exit branch 4\n",
    "        start_time = tf.timestamp()\n",
    "        temp = self.global_pool(x)\n",
    "        temp = self.dense_4(temp)\n",
    "        out_vector_list[4] = temp\n",
    "        comp_latency_list_exitbranch[4] = tf.timestamp() - start_time\n",
    "        \n",
    "        # mixed 3: 17 x 17 x 768 (bl3)\n",
    "        start_time = tf.timestamp()\n",
    "        branch3x3 = self.branch3x3_bl3(x)\n",
    "\n",
    "        branch3x3dbl = self.branch3x3dbl_bl3_0(x)\n",
    "        branch3x3dbl = self.branch3x3dbl_bl3_1(branch3x3dbl)\n",
    "        branch3x3dbl = self.branch3x3dbl_bl3_2(branch3x3dbl)\n",
    "        \n",
    "        branch_pool = self.branch_pool_bl3(x)\n",
    "        x = concatenate([branch3x3, branch3x3dbl, branch_pool], axis=channel_axis)\n",
    "        comp_latency_list_backbone[5] = tf.timestamp() - start_time\n",
    "        \n",
    "#         print(\"branch 5 \", x.shape)\n",
    "        ### *** exit branch 5\n",
    "        start_time = tf.timestamp()\n",
    "        temp = self.global_pool(x)\n",
    "        temp = self.dense_5(temp)\n",
    "        out_vector_list[5] = temp\n",
    "        comp_latency_list_exitbranch[5] = tf.timestamp() - start_time\n",
    "        \n",
    "\n",
    "        # mixed 4: 17 x 17 x 768 (bl4)\n",
    "        start_time = tf.timestamp()\n",
    "        branch1x1 = self.branch1x1_bl4(x)\n",
    "\n",
    "        branch7x7 = self.branch7x7_bl4_0(x)\n",
    "        branch7x7 = self.branch7x7_bl4_1(branch7x7)\n",
    "        branch7x7 = self.branch7x7_bl4_2(branch7x7)\n",
    "\n",
    "        branch7x7dbl = self.branch7x7dbl_bl4_0(x)\n",
    "        branch7x7dbl = self.branch7x7dbl_bl4_1(branch7x7dbl)\n",
    "        branch7x7dbl = self.branch7x7dbl_bl4_2(branch7x7dbl)\n",
    "        branch7x7dbl = self.branch7x7dbl_bl4_3(branch7x7dbl)\n",
    "        branch7x7dbl = self.branch7x7dbl_bl4_4(branch7x7dbl)\n",
    "\n",
    "        branch_pool = self.branch_pool_bl4(x)\n",
    "        branch_pool = self.branch_poolou4_bl4(branch_pool)\n",
    "        x = concatenate([branch1x1, branch7x7, branch7x7dbl, branch_pool], axis=channel_axis)\n",
    "        comp_latency_list_backbone[6] = tf.timestamp() - start_time\n",
    "\n",
    "#         print(\"branch 6 \", x.shape)\n",
    "        ### *** exit branch 6\n",
    "        start_time = tf.timestamp()\n",
    "        temp = self.global_pool(x)\n",
    "        temp = self.dense_6(temp)\n",
    "        out_vector_list[6] = temp\n",
    "        comp_latency_list_exitbranch[6] = tf.timestamp() - start_time\n",
    "        \n",
    "        \n",
    "        # mixed 5: 17 x 17 x 768 (bl5)\n",
    "        start_time = tf.timestamp()\n",
    "        branch1x1 = self.branch1x1_bl5(x)\n",
    "\n",
    "        branch7x7 = self.branch7x7_bl5_0(x)\n",
    "        branch7x7 = self.branch7x7_bl5_1(branch7x7)\n",
    "        branch7x7 = self.branch7x7_bl5_2(branch7x7)\n",
    "\n",
    "        branch7x7dbl = self.branch7x7dbl_bl5_0(x)\n",
    "        branch7x7dbl = self.branch7x7dbl_bl5_1(branch7x7dbl)\n",
    "        branch7x7dbl = self.branch7x7dbl_bl5_2(branch7x7dbl)\n",
    "        branch7x7dbl = self.branch7x7dbl_bl5_3(branch7x7dbl)\n",
    "        branch7x7dbl = self.branch7x7dbl_bl5_4(branch7x7dbl)\n",
    "\n",
    "        branch_pool = self.branch_pool_bl5(x)\n",
    "        branch_pool = self.branch_poolout_bl5(branch_pool)\n",
    "        x = concatenate([branch1x1, branch7x7, branch7x7dbl, branch_pool], axis=channel_axis)\n",
    "        comp_latency_list_backbone[7] = tf.timestamp() - start_time\n",
    "        \n",
    "#         print(\"branch 7 \", x.shape)\n",
    "        ### *** exit branch 7\n",
    "        start_time = tf.timestamp()\n",
    "        temp = self.global_pool(x)\n",
    "        temp = self.dense_7(temp)\n",
    "        out_vector_list[7] = temp\n",
    "        comp_latency_list_exitbranch[7] = tf.timestamp() - start_time\n",
    "        \n",
    "        \n",
    "        # mixed 6: 17 x 17 x 768 (bl6)\n",
    "        start_time = tf.timestamp()\n",
    "        branch1x1 = self.branch1x1_bl6(x)\n",
    "\n",
    "        branch7x7 = self.branch7x7_bl6_0(x)\n",
    "        branch7x7 = self.branch7x7_bl6_1(branch7x7)\n",
    "        branch7x7 = self.branch7x7_bl6_2(branch7x7)\n",
    "\n",
    "        branch7x7dbl = self.branch7x7dbl_bl6_0(x)\n",
    "        branch7x7dbl = self.branch7x7dbl_bl6_1(branch7x7dbl)\n",
    "        branch7x7dbl = self.branch7x7dbl_bl6_2(branch7x7dbl)\n",
    "        branch7x7dbl = self.branch7x7dbl_bl6_3(branch7x7dbl)\n",
    "        branch7x7dbl = self.branch7x7dbl_bl6_4(branch7x7dbl)\n",
    "\n",
    "        branch_pool = self.branch_pool_bl6(x)\n",
    "        branch_pool = self.branch_poolout_bl6(branch_pool)\n",
    "        x = concatenate([branch1x1, branch7x7, branch7x7dbl, branch_pool], axis=channel_axis)\n",
    "        comp_latency_list_backbone[8] = tf.timestamp() - start_time\n",
    "\n",
    "#         print(\"branch 8 \", x.shape)\n",
    "        ### *** exit branch 8\n",
    "        start_time = tf.timestamp()\n",
    "        temp = self.global_pool(x)\n",
    "        temp = self.dense_8(temp)\n",
    "        out_vector_list[8] = temp\n",
    "        comp_latency_list_exitbranch[8] = tf.timestamp() - start_time\n",
    "        \n",
    "            \n",
    "        # mixed 7: 17 x 17 x 768 (bl7)\n",
    "        start_time = tf.timestamp()\n",
    "        branch1x1 = self.branch1x1_bl7(x)\n",
    "\n",
    "        branch7x7 = self.branch7x7_bl7_0(x)\n",
    "        branch7x7 = self.branch7x7_bl7_1 (branch7x7)\n",
    "        branch7x7 = self.branch7x7_bl7_2(branch7x7)\n",
    "\n",
    "        branch7x7dbl = self.branch7x7dbl_bl7_0(x)\n",
    "        branch7x7dbl = self.branch7x7dbl_bl7_1(branch7x7dbl)\n",
    "        branch7x7dbl = self.branch7x7dbl_bl7_2(branch7x7dbl)\n",
    "        branch7x7dbl = self.branch7x7dbl_bl7_3(branch7x7dbl)\n",
    "        branch7x7dbl = self.branch7x7dbl_bl7_4(branch7x7dbl)\n",
    "\n",
    "        branch_pool = self.branch_pool_bl7(x)\n",
    "        branch_pool = self.branch_poolout_bl7(branch_pool)\n",
    "        x = concatenate([branch1x1, branch7x7, branch7x7dbl, branch_pool], axis=channel_axis)\n",
    "        comp_latency_list_backbone[9] = tf.timestamp() - start_time\n",
    "        \n",
    "#         print(\"branch 9 \", x.shape)\n",
    "        ### *** exit branch 9\n",
    "        start_time = tf.timestamp()\n",
    "        temp = self.global_pool(x)\n",
    "        temp = self.dense_9(temp)\n",
    "        out_vector_list[9] = temp\n",
    "        comp_latency_list_exitbranch[9] = tf.timestamp() - start_time\n",
    "        \n",
    "        # mixed 8: 8 x 8 x 1280 (bl8)\n",
    "        start_time = tf.timestamp()\n",
    "        branch3x3 = self.branch3x3_bl8(x)\n",
    "        branch3x3 = self.branch3x3_bl8_0(branch3x3)\n",
    "\n",
    "        branch7x7x3 = self.branch7x7x3_bl8_0(x)\n",
    "        branch7x7x3 = self.branch7x7x3_bl8_1(branch7x7x3)\n",
    "        branch7x7x3 = self.branch7x7x3_bl8_2(branch7x7x3)\n",
    "        branch7x7x3 = self.branch7x7x3_bl8_3(branch7x7x3)\n",
    "\n",
    "        branch_pool = self.branch_pool_bl8(x)\n",
    "        x = concatenate([branch3x3, branch7x7x3, branch_pool], axis=channel_axis)\n",
    "        comp_latency_list_backbone[10] = tf.timestamp() - start_time\n",
    "\n",
    "#         print(\"branch 10 \", x.shape)\n",
    "        ### *** exit branch 10\n",
    "        start_time = tf.timestamp()\n",
    "        temp = self.global_pool(x)\n",
    "        temp = self.dense_10(temp)\n",
    "        out_vector_list[10] = temp\n",
    "        comp_latency_list_exitbranch[10] = tf.timestamp() - start_time\n",
    "        \n",
    "        \n",
    "        # mixed 9: 8 x 8 x 2048 (bl9)\n",
    "        start_time = tf.timestamp()\n",
    "        branch1x1 =  self.branch1x1_bl9(x)\n",
    "\n",
    "        branch3x3 = self.branch3x3_bl9(x)\n",
    "        branch3x3_1 = self.branch3x3_1_bl9(branch3x3)\n",
    "        branch3x3_2 = self.branch3x3_2_bl9(branch3x3)\n",
    "        branch3x3 = concatenate([branch3x3_1, branch3x3_2], axis=channel_axis)\n",
    "\n",
    "        branch3x3dbl = self.branch3x3dbl_bl9(x)\n",
    "        branch3x3dbl = self.branch3x3dbl_bl9_0(branch3x3dbl)\n",
    "        branch3x3dbl_1 = self.branch3x3dbl_1_bl9(branch3x3dbl)\n",
    "        branch3x3dbl_2 = self.branch3x3dbl_2_bl9(branch3x3dbl)\n",
    "        branch3x3dbl = concatenate([branch3x3dbl_1, branch3x3dbl_2], axis=channel_axis)\n",
    "\n",
    "        branch_pool = self.branch_pool_bl9(x)\n",
    "        branch_pool = self.branch_poolout_bl9(branch_pool)\n",
    "        x = concatenate([branch1x1, branch3x3, branch3x3dbl, branch_pool], axis=channel_axis)\n",
    "        comp_latency_list_backbone[11] = tf.timestamp() - start_time\n",
    "        \n",
    "#         print(\"branch 11 \", x.shape)\n",
    "        ### *** exit branch 11\n",
    "        start_time = tf.timestamp()\n",
    "        temp = self.global_pool(x)\n",
    "        temp = self.dense_11(temp)\n",
    "        out_vector_list[11] = temp\n",
    "        comp_latency_list_exitbranch[11] = tf.timestamp() - start_time\n",
    "        \n",
    "        \n",
    "        # mixed 10: 8 x 8 x 2048 (bl10)\n",
    "        start_time = tf.timestamp()\n",
    "        branch1x1 = self.branch1x1_bl10(x)\n",
    "\n",
    "        branch3x3 = self.branch3x3_bl10(x)\n",
    "        branch3x3_1 = self.branch3x3_1_bl10(branch3x3)\n",
    "        branch3x3_2 = self.branch3x3_2_bl10(branch3x3)\n",
    "        branch3x3 = concatenate([branch3x3_1, branch3x3_2], axis=channel_axis)\n",
    "\n",
    "        branch3x3dbl = self.branch3x3dbl_bl10_0(x)\n",
    "        branch3x3dbl = self.branch3x3dbl_bl10_1(branch3x3dbl)\n",
    "        branch3x3dbl_1 = self.branch3x3dbl_1_bl10(branch3x3dbl)\n",
    "        branch3x3dbl_2 = self.branch3x3dbl_2_bl10(branch3x3dbl)\n",
    "        branch3x3dbl = concatenate([branch3x3dbl_1, branch3x3dbl_2], axis=channel_axis)\n",
    "\n",
    "        branch_pool = self.branch_pool_bl10(x)\n",
    "        branch_pool = self.branch_poolout_bl10(branch_pool)\n",
    "        x = concatenate([branch1x1, branch3x3, branch3x3dbl, branch_pool], axis=channel_axis)\n",
    "        comp_latency_list_backbone[12] = tf.timestamp() - start_time\n",
    "        \n",
    "#         print(\"branch 12 \", x.shape)\n",
    "        ### *** exit branch 12 last\n",
    "        start_time = tf.timestamp()\n",
    "        temp = self.global_pool(x)\n",
    "        temp = self.dense_last(temp)\n",
    "        out_vector_list[12] = temp\n",
    "        comp_latency_list_exitbranch[12] = tf.timestamp() - start_time\n",
    "        ##############################################\n",
    "            \n",
    "        if (inference_flag == 1000):\n",
    "            return(out_vector_list, comp_latency_list_backbone, comp_latency_list_exitbranch)\n",
    "        \n",
    "        \n",
    "        return out_vector_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e25ae7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 19s 74ms/step - loss: 6.4967 - output_1_loss: 1.2309 - output_2_loss: 0.9301 - output_3_loss: 0.5608 - output_4_loss: 0.4321 - output_5_loss: 0.3947 - output_6_loss: 0.4010 - output_7_loss: 0.3616 - output_8_loss: 0.3928 - output_9_loss: 0.3674 - output_10_loss: 0.3681 - output_11_loss: 0.3320 - output_12_loss: 0.3240 - output_13_loss: 0.4012 - output_1_accuracy: 0.5840 - output_2_accuracy: 0.6938 - output_3_accuracy: 0.8202 - output_4_accuracy: 0.8746 - output_5_accuracy: 0.8906 - output_6_accuracy: 0.9016 - output_7_accuracy: 0.9218 - output_8_accuracy: 0.9304 - output_9_accuracy: 0.9326 - output_10_accuracy: 0.9310 - output_11_accuracy: 0.9330 - output_12_accuracy: 0.9358 - output_13_accuracy: 0.9318\n"
     ]
    }
   ],
   "source": [
    "#### Inception V3 + CIFAR10 (299x299)\n",
    "##### load weight\n",
    "opt = tf.keras.optimizers.RMSprop(momentum=0.9)\n",
    "\n",
    "branch_number= 13\n",
    "\n",
    "ls = [CustomLoss(1) for i in range(branch_number)]\n",
    "\n",
    "model_CIFAR_Inception_V3 = CIFAR_Inception_V3(branch_number)\n",
    "model_CIFAR_Inception_V3.compile(optimizer=opt, loss=ls, metrics=['accuracy'])\n",
    "model_CIFAR_Inception_V3.load_weights('profiling_models/Inception_V3_13out_bs32_epoch100_lr0.01')\n",
    "model_CIFAR_Inception_V3.evaluate(test_it);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b551084",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### now the profiling part\n",
    "###### TRAIN PART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "249ffc0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computation latencies backbone(train data)    [2.75459888 1.32624567 5.12389028 5.02911969 5.01359507 4.0302824\n",
      " 7.54120809 7.10608516 7.08174134 7.31302761 5.15766109 7.87290069\n",
      " 7.76894309]\n",
      "computation latencies exitbranch(train data)    [0.54501376 0.4557634  0.49166145 0.49352409 0.49595615 0.50750211\n",
      " 0.51163939 0.50188097 0.50008883 0.50284579 0.52006973 0.50709085\n",
      " 0.50691931]\n",
      "&&&&& selected exit  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13]   &&&&&&\n",
      "------------------  1e-09 ------------------------\n",
      "exit rate per thresh  {4: 163, 5: 873, 6: 2933, 7: 7202, 8: 8524, 9: 1080, 10: 81, 11: 114, 12: 45, 13: 28985}\n",
      "------------------  0.052631527263157896 ------------------------\n",
      "exit rate per thresh  {1: 1277, 2: 5170, 3: 14852, 4: 11114, 5: 6877, 6: 4405, 7: 4232, 8: 1318, 9: 140, 10: 17, 11: 73, 12: 41, 13: 484}\n",
      "------------------  0.10526305352631579 ------------------------\n",
      "exit rate per thresh  {1: 2726, 2: 7960, 3: 16387, 4: 9975, 5: 5684, 6: 3320, 7: 2851, 8: 726, 9: 70, 10: 17, 11: 34, 12: 21, 13: 229}\n",
      "------------------  0.1578945797894737 ------------------------\n",
      "exit rate per thresh  {1: 4386, 2: 9913, 3: 16824, 4: 9018, 5: 4662, 6: 2591, 7: 1991, 8: 436, 9: 44, 10: 8, 11: 29, 12: 8, 13: 90}\n",
      "------------------  0.21052610605263158 ------------------------\n",
      "exit rate per thresh  {1: 6343, 2: 11509, 3: 16610, 4: 8049, 5: 3794, 6: 1989, 7: 1358, 8: 256, 9: 33, 10: 4, 11: 11, 12: 6, 13: 38}\n",
      "------------------  0.26315763231578954 ------------------------\n",
      "exit rate per thresh  {1: 8820, 2: 12685, 3: 16037, 4: 6914, 5: 3066, 6: 1434, 7: 862, 8: 141, 9: 17, 10: 3, 11: 4, 12: 3, 13: 14}\n",
      "------------------  0.3157891585789474 ------------------------\n",
      "exit rate per thresh  {1: 11929, 2: 13673, 3: 14893, 4: 5747, 5: 2242, 6: 946, 7: 490, 8: 68, 9: 3, 10: 1, 11: 3, 12: 2, 13: 3}\n",
      "------------------  0.3684206848421053 ------------------------\n",
      "exit rate per thresh  {1: 15476, 2: 14354, 3: 13251, 4: 4500, 5: 1546, 6: 562, 7: 282, 8: 24, 9: 2, 12: 2, 13: 1}\n",
      "------------------  0.4210522111052632 ------------------------\n",
      "exit rate per thresh  {1: 19149, 2: 14549, 3: 11416, 4: 3412, 5: 1007, 6: 328, 7: 134, 8: 5}\n",
      "------------------  0.4736837373684211 ------------------------\n",
      "exit rate per thresh  {1: 22964, 2: 14386, 3: 9466, 4: 2348, 5: 623, 6: 157, 7: 55, 8: 1}\n",
      "------------------  0.526315263631579 ------------------------\n",
      "exit rate per thresh  {1: 27048, 2: 13666, 3: 7409, 4: 1460, 5: 326, 6: 71, 7: 20}\n",
      "------------------  0.5789467898947368 ------------------------\n",
      "exit rate per thresh  {1: 31212, 2: 12433, 3: 5399, 4: 785, 5: 142, 6: 22, 7: 7}\n",
      "------------------  0.6315783161578947 ------------------------\n",
      "exit rate per thresh  {1: 35561, 2: 10414, 3: 3592, 4: 370, 5: 51, 6: 10, 7: 2}\n",
      "------------------  0.6842098424210526 ------------------------\n",
      "exit rate per thresh  {1: 39815, 2: 7950, 3: 2074, 4: 138, 5: 20, 6: 3}\n",
      "------------------  0.7368413686842105 ------------------------\n",
      "exit rate per thresh  {1: 43512, 2: 5428, 3: 1014, 4: 41, 5: 4, 6: 1}\n",
      "------------------  0.7894728949473684 ------------------------\n",
      "exit rate per thresh  {1: 46386, 2: 3215, 3: 396, 4: 3}\n",
      "------------------  0.8421044212105263 ------------------------\n",
      "exit rate per thresh  {1: 48414, 2: 1492, 3: 93, 4: 1}\n",
      "------------------  0.8947359474736842 ------------------------\n",
      "exit rate per thresh  {1: 49611, 2: 385, 3: 4}\n",
      "------------------  0.9473674737368422 ------------------------\n",
      "exit rate per thresh  {1: 49974, 2: 26}\n",
      "------------------  0.999999 ------------------------\n",
      "exit rate per thresh  {1: 50000}\n",
      "------------------------------------------------------------------\n",
      "exit rate average  [5.14603e-01 1.59208e-01 1.49717e-01 6.40380e-02 3.09170e-02 1.87720e-02\n",
      " 1.94860e-02 1.14990e-02 1.38900e-03 1.31000e-04 2.68000e-04 1.28000e-04\n",
      " 2.98440e-02]\n"
     ]
    }
   ],
   "source": [
    "##### passing TRAIN samples through model\n",
    "##### this is to save computation time and exit rates for all the possible branches\n",
    "\n",
    "per_sample_label_list = []\n",
    "per_sample_out_vector_list = []\n",
    "per_sample_comp_latency_backbone_list = []\n",
    "per_sample_comp_latency_exitbranch_list = []\n",
    "\n",
    "\n",
    "#### saving intermediate data once\n",
    "for i in range (len(train_it)):\n",
    "    temp_batch = train_it[i]\n",
    "\n",
    "    for j in range (len(temp_batch[0])):\n",
    "        pic = temp_batch[0][j]\n",
    "        label = temp_batch[1][j]\n",
    "        per_sample_label_list.append(np.array(label).reshape(1,10))\n",
    "\n",
    "        res = model_CIFAR_Inception_V3(np.array(pic.reshape(1,image_resize,image_resize,3)), training = 1000)\n",
    "   \n",
    "        per_sample_out_vector_list.append(res[0])\n",
    "        per_sample_comp_latency_backbone_list.append(res[1])\n",
    "        per_sample_comp_latency_exitbranch_list.append(res[2])\n",
    "\n",
    "print (\"computation latencies backbone(train data)   \", np.mean(per_sample_comp_latency_backbone_list, axis=0)*1000)\n",
    "print (\"computation latencies exitbranch(train data)   \", np.mean(per_sample_comp_latency_exitbranch_list, axis=0)*1000)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### passing TRAIN samples through model\n",
    "##### this is to save computation time and exit rates for all the possible branches\n",
    "\n",
    "entropy_threshold_list = np.linspace(0.000000001, 0.999999, num=20)\n",
    "\n",
    "### all possible branches, and chosen number\n",
    "chosen_number = branch_number\n",
    "I = list(range(1, branch_number+1))\n",
    "\n",
    "#### number of train samples for simulation\n",
    "sample_number = train_it.samples\n",
    "\n",
    "\n",
    "\n",
    "#### per placement, in this case it is only 1, all the possible branches\n",
    "for item in combinations(I, chosen_number):\n",
    "    placement = list(np.array(item))\n",
    "    print (\"&&&&& selected exit \", placement , \"  &&&&&&\")\n",
    "        \n",
    "    ent_exitrate_list = []\n",
    "\n",
    "    ##### per threshold \n",
    "    for thresh in entropy_threshold_list:\n",
    "        print (\"------------------ \", thresh, \"------------------------\")\n",
    "\n",
    "        threshold_exit = []\n",
    "        threshold_exitrate = [[] for i in range(branch_number)]\n",
    "\n",
    "        ##### per sample\n",
    "        for sample in range (sample_number):\n",
    "\n",
    "            #### determining the exit branch based on entropy of the output and thresh\n",
    "            for exit in range(branch_number):\n",
    "                out = per_sample_out_vector_list[sample][exit]\n",
    "                entropy = -1 * tf.math.reduce_sum((tf.math.log(out) * out)/ np.log(out.shape[1]))\n",
    "\n",
    "                if (entropy < thresh or exit+1==branch_number):\n",
    "                    threshold_exit.append(exit+1)\n",
    "                    break\n",
    "\n",
    "\n",
    "        # handling exit percentage part\n",
    "        unique, counts = np.unique(threshold_exit, return_counts=True)\n",
    "        exitper_list_dict = dict(zip(unique, counts))\n",
    "        print (\"exit rate per thresh \", exitper_list_dict)\n",
    "\n",
    "        for i in range(branch_number):\n",
    "            if (exitper_list_dict.get(placement[i]) is None):\n",
    "                threshold_exitrate[i].append (0)\n",
    "            else:\n",
    "                threshold_exitrate[i].append(exitper_list_dict.get(placement[i]))\n",
    "\n",
    "\n",
    "        ent_exitrate_list.append(np.mean(threshold_exitrate, axis=1)/sample_number)\n",
    "\n",
    "    print(\"------------------------------------------------------------------\")\n",
    "    print(\"exit rate average \", np.mean(ent_exitrate_list, axis=0))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8a3b1c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### TEST PART, FOR SIMULATION ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1407531a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### passing TEST samples through model once and save the intermediate data\n",
    "#### this is for doing the simulation\n",
    "\n",
    "per_sample_label_list = []\n",
    "per_sample_out_vector_list = []\n",
    "per_sample_comp_latency_backbone_list = []\n",
    "per_sample_comp_latency_exitbranch_list = []\n",
    "\n",
    "for i in range (len(test_it)):\n",
    "    temp_batch = test_it[i]\n",
    "\n",
    "    for j in range (len(temp_batch[0])):\n",
    "        pic = temp_batch[0][j]\n",
    "        label = temp_batch[1][j]\n",
    "        per_sample_label_list.append(np.array(label).reshape(1,10))\n",
    "\n",
    "        res = model_CIFAR_Inception_V3(np.array(pic.reshape(1,image_resize,image_resize,3)), training = 1000)\n",
    "   \n",
    "        per_sample_out_vector_list.append(res[0])\n",
    "        per_sample_comp_latency_backbone_list.append(res[1])\n",
    "        per_sample_comp_latency_exitbranch_list.append(res[2])\n",
    "        \n",
    "print (\"computation latencies backbone(test data)   \", np.mean(per_sample_comp_latency_backbone_list, axis=0)*1000)\n",
    "print (\"computation latencies exitbranch(test data)   \", np.mean(per_sample_comp_latency_exitbranch_list, axis=0)*1000)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
