{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "698f5d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import add, Input, Dense, Conv2D, MaxPooling2D, AveragePooling2D, ZeroPadding2D, Dropout, Flatten, Concatenate, Reshape, Activation, BatchNormalization, GlobalAveragePooling2D, ZeroPadding2D\n",
    "from tensorflow.nn import local_response_normalization\n",
    "from tensorflow.python.keras.layers.merge import concatenate\n",
    "from tensorflow.keras.activations import relu\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import matplotlib\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler\n",
    "from tensorflow.keras.regularizers import l2, l1, l1_l2\n",
    "from itertools import permutations, combinations\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b32aa383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device mapping:\n",
      "/job:localhost/replica:0/task:0/device:GPU:0 -> device: 0, name: GeForce RTX 3080, pci bus id: 0000:41:00.0, compute capability: 8.6\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True  # dynamically grow the memory used on the GPU\n",
    "config.log_device_placement = True  # to log device placement (on which device the operation ran)\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.60\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "tf.compat.v1.keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67aa2065",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 19999 images belonging to 2 classes.\n",
      "Found 2500 images belonging to 2 classes.\n",
      "Found 2499 images belonging to 2 classes.\n",
      "data batch shape: (32, 32, 32, 3)\n",
      "labels batch shape: (32, 2)\n"
     ]
    }
   ],
   "source": [
    "global_batch_size = 32\n",
    "image_resize = 32\n",
    "\n",
    "########## Train\n",
    "# datagen = ImageDataGenerator(rescale=1./255, rotation_range = 20, horizontal_flip = True, vertical_flip=True, height_shift_range = 0.2,\n",
    "#                                    width_shift_range = 0.2, zoom_range = 0.2)\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_it = datagen.flow_from_directory(\n",
    "        'cat_dog/train',\n",
    "        class_mode='categorical',\n",
    "        target_size=(image_resize, image_resize),\n",
    "        batch_size=global_batch_size)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "############ Test\n",
    "test_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.5)\n",
    "\n",
    "validation_it = test_datagen.flow_from_directory(\n",
    "        'cat_dog/test',\n",
    "        class_mode='categorical',\n",
    "        target_size=(image_resize, image_resize),\n",
    "        batch_size=global_batch_size,\n",
    "        subset = \"training\",seed = 545)\n",
    "\n",
    "test_it = test_datagen.flow_from_directory(\n",
    "        'cat_dog/test',\n",
    "        class_mode='categorical',\n",
    "        target_size=(image_resize, image_resize),\n",
    "        batch_size=global_batch_size,\n",
    "        subset = \"validation\",\n",
    "        seed = 545)\n",
    "\n",
    "\n",
    "for data_batch, labels_batch in train_it:\n",
    "    print('data batch shape:', data_batch.shape)\n",
    "    print('labels batch shape:', labels_batch.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1e66c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLoss(keras.losses.Loss):\n",
    "    def __init__(self, factor):\n",
    "        super().__init__()\n",
    "        self.factor = factor\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        ce = tf.keras.losses.categorical_crossentropy(y_true, y_pred)\n",
    "        return ce * self.factor\n",
    "    \n",
    "class Residual_block(tf.keras.Model):\n",
    "    def __init__(self, num_channels, use_1x1conv=False, strides=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = Conv2D(num_channels, kernel_size=3, padding='same', strides=strides, kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001), bias_regularizer=l2(0.00001))\n",
    "        self.conv2 = Conv2D(num_channels, kernel_size=3, padding='same', kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001), bias_regularizer=l2(0.00001))\n",
    "        self.conv3 = None\n",
    "        \n",
    "        if use_1x1conv:\n",
    "            self.conv3 = Conv2D(num_channels, kernel_size=1, strides=strides, kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001), bias_regularizer=l2(0.00001))\n",
    "            \n",
    "        self.bn1 = BatchNormalization()\n",
    "        self.bn2 = BatchNormalization()\n",
    "        \n",
    "    def call(self, X, training):\n",
    "        \n",
    "        if (training != False and training != True):\n",
    "            training = False\n",
    "        \n",
    "        Y = self.conv1(X)\n",
    "        Y = self.bn1 (Y, training = training)\n",
    "        Y = relu(Y)\n",
    "        Y = self.conv2(Y)\n",
    "        Y = self.bn2 (Y, training = training)\n",
    "        \n",
    "        if self.conv3 is not None:\n",
    "            X = self.conv3(X)\n",
    "            \n",
    "        Y += X\n",
    "        Y = relu(Y)\n",
    "        return Y\n",
    "\n",
    "\n",
    "class CIFAR_ResNet(tf.keras.Model):\n",
    "    def __init__(self, model_n, branch_number):\n",
    "        super(CIFAR_ResNet, self).__init__()\n",
    "        \n",
    "        self.model_n = model_n\n",
    "        self.branch_number = branch_number\n",
    "        self.residual_layers = []\n",
    "        \n",
    "        ######## Begining Layers\n",
    "        self.conv1 = Conv2D(16, kernel_size=3, padding='same',kernel_initializer='he_uniform', input_shape=(image_resize, image_resize, 3), kernel_regularizer=l2(0.00001), bias_regularizer=l2(0.00001))\n",
    "        self.bn1 = BatchNormalization()\n",
    "        \n",
    "        \n",
    "        ######## ResNet layers\n",
    "        ### first block, 16 channels\n",
    "        for i in range(self.model_n):\n",
    "            self.residual_layers.append(Residual_block(16))\n",
    "            \n",
    "        ### second block, 32 channels\n",
    "        for i in range(self.model_n):\n",
    "            if i == 0:\n",
    "                self.residual_layers.append(Residual_block(32, use_1x1conv=True, strides=2))\n",
    "            else:\n",
    "                self.residual_layers.append(Residual_block(32))\n",
    "                \n",
    "        ### third block, 64 channels\n",
    "        self.residual_layers_block3 = []\n",
    "        for i in range(self.model_n):\n",
    "            if i == 0:\n",
    "                self.residual_layers.append(Residual_block(64, use_1x1conv=True, strides=2))\n",
    "            else:\n",
    "                self.residual_layers.append(Residual_block(64))\n",
    "\n",
    "        \n",
    "        ######## OUTPUT Layers\n",
    "        self.pool_out = GlobalAveragePooling2D()\n",
    "        self.flat_out = Flatten()\n",
    "\n",
    "        self.dense_layers = []\n",
    "        for i in range(self.branch_number):\n",
    "            self.dense_layers.append(Dense(2, kernel_initializer='he_uniform', kernel_regularizer=l2(0.00001), bias_regularizer=l2(0.00001), activation='softmax'))\n",
    "        \n",
    "\n",
    "    def call(self, inputs, training):\n",
    "        inference_flag = -1000\n",
    "        layer_ind_counter = 0\n",
    "        comp_latency_list_backbone = [0 for i in range(self.branch_number)]\n",
    "        comp_latency_list_exitbranch = [0 for i in range(self.branch_number)]\n",
    "        out_vector_list = [[] for i in range(self.branch_number)]\n",
    "        \n",
    "        if (training != False and training != True):\n",
    "            inference_flag = 1000\n",
    "            training = False\n",
    "            \n",
    "            \n",
    "        ##### Begining layers\n",
    "        start_time = tf.timestamp()\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.bn1 (x, training = training)\n",
    "        x = relu (x)\n",
    "        comp_latency_list_backbone[layer_ind_counter] = tf.timestamp() - start_time\n",
    "        \n",
    "        \n",
    "        # exit branch\n",
    "        start_time = tf.timestamp()\n",
    "        temp = self.pool_out(x)\n",
    "        temp = self.flat_out(temp)\n",
    "        out_vector_list[layer_ind_counter] = self.dense_layers[layer_ind_counter](temp)\n",
    "        comp_latency_list_exitbranch[layer_ind_counter] = tf.timestamp() - start_time\n",
    "        \n",
    "        \n",
    "        \n",
    "        ##### ResNet Layers\n",
    "        for layer in self.residual_layers:\n",
    "            layer_ind_counter += 1\n",
    "            start_time = tf.timestamp()\n",
    "            x = layer (x)\n",
    "            comp_latency_list_backbone[layer_ind_counter] = tf.timestamp() - start_time\n",
    "            \n",
    "            # add exit branch after each resnet block\n",
    "            start_time = tf.timestamp()\n",
    "            temp = self.pool_out(x)\n",
    "            temp = self.flat_out(temp)\n",
    "            out_vector_list[layer_ind_counter] = self.dense_layers[layer_ind_counter](temp)\n",
    "            comp_latency_list_exitbranch[layer_ind_counter] = tf.timestamp() - start_time\n",
    "            \n",
    "\n",
    "\n",
    "        if (inference_flag == 1000):\n",
    "            return(out_vector_list, comp_latency_list_backbone, comp_latency_list_exitbranch)\n",
    "        \n",
    "        \n",
    "        return out_vector_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26ea6125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 8s 78ms/step - loss: 4.8499 - output_1_loss: 0.7336 - output_2_loss: 0.5925 - output_3_loss: 0.5829 - output_4_loss: 0.5133 - output_5_loss: 0.4583 - output_6_loss: 0.4010 - output_7_loss: 0.3682 - output_8_loss: 0.3505 - output_9_loss: 0.3407 - output_10_loss: 0.3369 - output_1_accuracy: 0.5890 - output_2_accuracy: 0.7083 - output_3_accuracy: 0.7479 - output_4_accuracy: 0.7827 - output_5_accuracy: 0.8115 - output_6_accuracy: 0.8375 - output_7_accuracy: 0.8503 - output_8_accuracy: 0.8567 - output_9_accuracy: 0.8543 - output_10_accuracy: 0.8575\n"
     ]
    }
   ],
   "source": [
    "##### ResNet20 + cat & dog (32x32)\n",
    "\n",
    "##### load weight\n",
    "opt = tf.keras.optimizers.SGD(momentum=0.9)\n",
    "\n",
    "##### for ResNet20\n",
    "branch_number= 10\n",
    "model_n = 3\n",
    "\n",
    "ls = [CustomLoss(1) for i in range(branch_number)]\n",
    "\n",
    "model_CIFAR_ResNet = CIFAR_ResNet(model_n,branch_number)\n",
    "model_CIFAR_ResNet.compile(optimizer=opt, loss=ls, metrics=['accuracy'])\n",
    "model_CIFAR_ResNet.load_weights('profiling_models/ResNet20_10out_bs32_epoch500_lr0.01_catdog(32)')\n",
    "model_CIFAR_ResNet.evaluate(test_it);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e289f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "79/79 [==============================] - 8s 68ms/step - loss: 3.1698 - output_1_loss: 0.6294 - output_2_loss: 0.5064 - output_3_loss: 0.3978 - output_4_loss: 0.3248 - output_5_loss: 0.2544 - output_6_loss: 0.2137 - output_7_loss: 0.1955 - output_8_loss: 0.1828 - output_9_loss: 0.1751 - output_10_loss: 0.1727 - output_1_accuracy: 0.6371 - output_2_accuracy: 0.7687 - output_3_accuracy: 0.8243 - output_4_accuracy: 0.8583 - output_5_accuracy: 0.8900 - output_6_accuracy: 0.9144 - output_7_accuracy: 0.9208 - output_8_accuracy: 0.9292 - output_9_accuracy: 0.9372 - output_10_accuracy: 0.9372\n"
     ]
    }
   ],
   "source": [
    "##### ResNet20 + cat & dog (128x128)\n",
    "\n",
    "##### load weight\n",
    "opt = tf.keras.optimizers.SGD(momentum=0.9)\n",
    "\n",
    "##### for ResNet20\n",
    "branch_number= 10\n",
    "model_n = 3\n",
    "\n",
    "ls = [CustomLoss(1) for i in range(branch_number)]\n",
    "\n",
    "model_CIFAR_ResNet = CIFAR_ResNet(model_n,branch_number)\n",
    "model_CIFAR_ResNet.compile(optimizer=opt, loss=ls, metrics=['accuracy'])\n",
    "model_CIFAR_ResNet.load_weights('profiling_models/ResNet20_10out_bs32_epoch200_lr0.01_catdog(128)')\n",
    "model_CIFAR_ResNet.evaluate(test_it);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f37182b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### now the profiling part\n",
    "###### TRAIN PART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f18b0e90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%%%%%%%%%%%%%%%%%%%%%% ResNet20 + cat ans dog(32x32) %%%%%%%%%%%%%%%%%%%%%%%%%%%%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maryamebr/anaconda3/envs/new-tf-gpu/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:793: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computation latencies backbone(train data)    [1.00057505 1.52657419 1.33259182 1.3143112  1.67784431 1.35417646\n",
      " 1.34030226 1.58788354 1.30361067 1.29685041]\n",
      "computation latencies exitbranch(train data)    [0.55071364 0.55881715 0.5637968  0.55248329 0.55227588 0.54661874\n",
      " 0.54181743 0.54673773 0.54091606 0.53955897]\n",
      "&&&&& selected exit  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]   &&&&&&\n",
      "------------------  1e-09 ------------------------\n",
      "exit rate per thresh  {3: 3, 10: 19996}\n",
      "------------------  0.052631527263157896 ------------------------\n",
      "exit rate per thresh  {1: 217, 2: 1392, 3: 2210, 4: 1256, 5: 1159, 6: 1740, 7: 897, 8: 631, 9: 238, 10: 10259}\n",
      "------------------  0.10526305352631579 ------------------------\n",
      "exit rate per thresh  {1: 518, 2: 1876, 3: 2919, 4: 1585, 5: 1252, 6: 1852, 7: 849, 8: 569, 9: 262, 10: 8317}\n",
      "------------------  0.1578945797894737 ------------------------\n",
      "exit rate per thresh  {1: 878, 2: 2264, 3: 3280, 4: 1779, 5: 1293, 6: 1832, 7: 801, 8: 586, 9: 227, 10: 7059}\n",
      "------------------  0.21052610605263158 ------------------------\n",
      "exit rate per thresh  {1: 1237, 2: 2632, 3: 3552, 4: 1888, 5: 1299, 6: 1779, 7: 735, 8: 567, 9: 254, 10: 6056}\n",
      "------------------  0.26315763231578954 ------------------------\n",
      "exit rate per thresh  {1: 1642, 2: 2910, 3: 3748, 4: 2017, 5: 1287, 6: 1771, 7: 685, 8: 519, 9: 228, 10: 5192}\n",
      "------------------  0.3157891585789474 ------------------------\n",
      "exit rate per thresh  {1: 2081, 2: 3178, 3: 3852, 4: 2086, 5: 1241, 6: 1733, 7: 685, 8: 470, 9: 208, 10: 4465}\n",
      "------------------  0.3684206848421053 ------------------------\n",
      "exit rate per thresh  {1: 2594, 2: 3403, 3: 3909, 4: 2092, 5: 1238, 6: 1654, 7: 619, 8: 458, 9: 199, 10: 3833}\n",
      "------------------  0.4210522111052632 ------------------------\n",
      "exit rate per thresh  {1: 3134, 2: 3593, 3: 4007, 4: 2081, 5: 1206, 6: 1537, 7: 607, 8: 429, 9: 184, 10: 3221}\n",
      "------------------  0.4736837373684211 ------------------------\n",
      "exit rate per thresh  {1: 3731, 2: 3822, 3: 4025, 4: 2045, 5: 1155, 6: 1409, 7: 549, 8: 399, 9: 178, 10: 2686}\n",
      "------------------  0.526315263631579 ------------------------\n",
      "exit rate per thresh  {1: 4387, 2: 4045, 3: 3997, 4: 1978, 5: 1063, 6: 1311, 7: 486, 8: 348, 9: 174, 10: 2210}\n",
      "------------------  0.5789467898947368 ------------------------\n",
      "exit rate per thresh  {1: 5092, 2: 4221, 3: 3949, 4: 1900, 5: 999, 6: 1190, 7: 446, 8: 325, 9: 128, 10: 1749}\n",
      "------------------  0.6315783161578947 ------------------------\n",
      "exit rate per thresh  {1: 5905, 2: 4357, 3: 3865, 4: 1778, 5: 941, 6: 1046, 7: 389, 8: 259, 9: 115, 10: 1344}\n",
      "------------------  0.6842098424210526 ------------------------\n",
      "exit rate per thresh  {1: 6768, 2: 4503, 3: 3672, 4: 1639, 5: 860, 6: 909, 7: 341, 8: 211, 9: 86, 10: 1010}\n",
      "------------------  0.7368413686842105 ------------------------\n",
      "exit rate per thresh  {1: 7739, 2: 4636, 3: 3485, 4: 1434, 5: 751, 6: 744, 7: 273, 8: 171, 9: 70, 10: 696}\n",
      "------------------  0.7894728949473684 ------------------------\n",
      "exit rate per thresh  {1: 8818, 2: 4771, 3: 3107, 4: 1256, 5: 619, 6: 604, 7: 212, 8: 125, 9: 54, 10: 433}\n",
      "------------------  0.8421044212105263 ------------------------\n",
      "exit rate per thresh  {1: 10151, 2: 4735, 3: 2708, 4: 1006, 5: 484, 6: 430, 7: 145, 8: 75, 9: 39, 10: 226}\n",
      "------------------  0.8947359474736842 ------------------------\n",
      "exit rate per thresh  {1: 11779, 2: 4590, 3: 2149, 4: 733, 5: 294, 6: 246, 7: 66, 8: 58, 9: 19, 10: 65}\n",
      "------------------  0.9473674737368422 ------------------------\n",
      "exit rate per thresh  {1: 14028, 2: 3969, 3: 1411, 4: 351, 5: 127, 6: 72, 7: 18, 8: 10, 9: 3, 10: 10}\n",
      "------------------  0.999999 ------------------------\n",
      "exit rate per thresh  {1: 19967, 2: 32}\n",
      "------------------------------------------------------------------\n",
      "exit rate average  [0.27667883 0.16233062 0.14962748 0.07226361 0.04317216 0.05465023\n",
      " 0.0220086  0.01552578 0.00666533 0.19707735]\n"
     ]
    }
   ],
   "source": [
    "##### passing TRAIN samples through model\n",
    "##### this is to save computation time and exit rates for all the possible branches\n",
    "print(\"%%%%%%%%%%%%%%%%%%%%%%% ResNet20 + cat ans dog(32x32) %%%%%%%%%%%%%%%%%%%%%%%%%%%%\")\n",
    "per_sample_label_list = []\n",
    "per_sample_out_vector_list = []\n",
    "per_sample_comp_latency_backbone_list = []\n",
    "per_sample_comp_latency_exitbranch_list = []\n",
    "\n",
    "\n",
    "#### saving intermediate data once\n",
    "for i in range (len(train_it)):\n",
    "    temp_batch = train_it[i]\n",
    "\n",
    "    for j in range (len(temp_batch[0])):\n",
    "        pic = temp_batch[0][j]\n",
    "        label = temp_batch[1][j]\n",
    "        per_sample_label_list.append(np.array(label).reshape(1,2))\n",
    "\n",
    "        res = model_CIFAR_ResNet(np.array(pic.reshape(1,image_resize,image_resize,3)), training = 1000)\n",
    "   \n",
    "        per_sample_out_vector_list.append(res[0])\n",
    "        per_sample_comp_latency_backbone_list.append(res[1])\n",
    "        per_sample_comp_latency_exitbranch_list.append(res[2])\n",
    "\n",
    "print (\"computation latencies backbone(train data)   \", np.mean(per_sample_comp_latency_backbone_list, axis=0)*1000)\n",
    "print (\"computation latencies exitbranch(train data)   \", np.mean(per_sample_comp_latency_exitbranch_list, axis=0)*1000)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### passing TRAIN samples through model\n",
    "##### this is to save computation time and exit rates for all the possible branches\n",
    "\n",
    "entropy_threshold_list = np.linspace(0.000000001, 0.999999, num=20)\n",
    "\n",
    "### all possible branches, and chosen number\n",
    "chosen_number = branch_number\n",
    "I = list(range(1, branch_number+1))\n",
    "\n",
    "#### number of train samples for simulation\n",
    "sample_number = train_it.samples\n",
    "\n",
    "\n",
    "\n",
    "#### per placement, in this case it is only 1, all the possible branches\n",
    "for item in combinations(I, chosen_number):\n",
    "    placement = list(np.array(item))\n",
    "    print (\"&&&&& selected exit \", placement , \"  &&&&&&\")\n",
    "        \n",
    "    ent_exitrate_list = []\n",
    "\n",
    "    ##### per threshold \n",
    "    for thresh in entropy_threshold_list:\n",
    "        print (\"------------------ \", thresh, \"------------------------\")\n",
    "\n",
    "        threshold_exit = []\n",
    "        threshold_exitrate = [[] for i in range(branch_number)]\n",
    "\n",
    "        ##### per sample\n",
    "        for sample in range (sample_number):\n",
    "\n",
    "            #### determining the exit branch based on entropy of the output and thresh\n",
    "            for exit in range(branch_number):\n",
    "                out = per_sample_out_vector_list[sample][exit]\n",
    "                entropy = -1 * tf.math.reduce_sum((tf.math.log(out) * out)/ np.log(out.shape[1]))\n",
    "\n",
    "                if (entropy < thresh or exit+1==branch_number):\n",
    "                    threshold_exit.append(exit+1)\n",
    "                    break\n",
    "\n",
    "\n",
    "        # handling exit percentage part\n",
    "        unique, counts = np.unique(threshold_exit, return_counts=True)\n",
    "        exitper_list_dict = dict(zip(unique, counts))\n",
    "        print (\"exit rate per thresh \", exitper_list_dict)\n",
    "\n",
    "        for i in range(branch_number):\n",
    "            if (exitper_list_dict.get(placement[i]) is None):\n",
    "                threshold_exitrate[i].append (0)\n",
    "            else:\n",
    "                threshold_exitrate[i].append(exitper_list_dict.get(placement[i]))\n",
    "\n",
    "\n",
    "        ent_exitrate_list.append(np.mean(threshold_exitrate, axis=1)/sample_number)\n",
    "\n",
    "    print(\"------------------------------------------------------------------\")\n",
    "    print(\"exit rate average \", np.mean(ent_exitrate_list, axis=0))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297e8e41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a34828d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%%%%%%%%%%%%%%%%%%%%%%% ResNet20 + cat ans dog(128x128) %%%%%%%%%%%%%%%%%%%%%%%%%%%%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/maryamebr/anaconda3/envs/new-tf-gpu/lib/python3.7/site-packages/PIL/TiffImagePlugin.py:793: UserWarning: Truncated File Read\n",
      "  warnings.warn(str(msg))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computation latencies backbone(train data)    [1.05533315 1.59532795 1.40126899 1.3827306  1.6223228  1.34523489\n",
      " 1.33511933 1.58681718 1.34406202 1.33806372]\n",
      "computation latencies exitbranch(train data)    [0.55596838 0.55857674 0.56180903 0.54995784 0.54561086 0.5383982\n",
      " 0.53693254 0.54295068 0.54104106 0.53888817]\n",
      "&&&&& selected exit  [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]   &&&&&&\n",
      "------------------  1e-09 ------------------------\n",
      "exit rate per thresh  {7: 15, 8: 41, 9: 24, 10: 19919}\n",
      "------------------  0.052631527263157896 ------------------------\n",
      "exit rate per thresh  {1: 1, 2: 844, 3: 945, 4: 2030, 5: 2899, 6: 2450, 7: 1294, 8: 1154, 9: 692, 10: 7690}\n",
      "------------------  0.10526305352631579 ------------------------\n",
      "exit rate per thresh  {1: 6, 2: 1284, 3: 1634, 4: 2758, 5: 3218, 6: 2304, 7: 1098, 8: 1006, 9: 595, 10: 6096}\n",
      "------------------  0.1578945797894737 ------------------------\n",
      "exit rate per thresh  {1: 26, 2: 1689, 3: 2280, 4: 3132, 5: 3234, 6: 2141, 7: 1012, 8: 872, 9: 498, 10: 5115}\n",
      "------------------  0.21052610605263158 ------------------------\n",
      "exit rate per thresh  {1: 60, 2: 2084, 3: 2881, 4: 3326, 5: 3153, 6: 1947, 7: 975, 8: 724, 9: 452, 10: 4397}\n",
      "------------------  0.26315763231578954 ------------------------\n",
      "exit rate per thresh  {1: 106, 2: 2459, 3: 3431, 4: 3433, 5: 3017, 6: 1820, 7: 873, 8: 629, 9: 390, 10: 3841}\n",
      "------------------  0.3157891585789474 ------------------------\n",
      "exit rate per thresh  {1: 164, 2: 2822, 3: 3900, 4: 3493, 5: 2845, 6: 1762, 7: 762, 8: 567, 9: 357, 10: 3327}\n",
      "------------------  0.3684206848421053 ------------------------\n",
      "exit rate per thresh  {1: 243, 2: 3237, 3: 4328, 4: 3444, 5: 2695, 6: 1632, 7: 694, 8: 498, 9: 365, 10: 2863}\n",
      "------------------  0.4210522111052632 ------------------------\n",
      "exit rate per thresh  {1: 339, 2: 3649, 3: 4691, 4: 3379, 5: 2562, 6: 1497, 7: 642, 8: 450, 9: 307, 10: 2483}\n",
      "------------------  0.4736837373684211 ------------------------\n",
      "exit rate per thresh  {1: 469, 2: 4110, 3: 4962, 4: 3259, 5: 2390, 6: 1429, 7: 574, 8: 419, 9: 259, 10: 2128}\n",
      "------------------  0.526315263631579 ------------------------\n",
      "exit rate per thresh  {1: 621, 2: 4598, 3: 5198, 4: 3163, 5: 2217, 6: 1318, 7: 499, 8: 366, 9: 237, 10: 1782}\n",
      "------------------  0.5789467898947368 ------------------------\n",
      "exit rate per thresh  {1: 831, 2: 5137, 3: 5353, 4: 3026, 5: 2056, 6: 1160, 7: 445, 8: 295, 9: 204, 10: 1492}\n",
      "------------------  0.6315783161578947 ------------------------\n",
      "exit rate per thresh  {1: 1084, 2: 5708, 3: 5434, 4: 2897, 5: 1831, 6: 1053, 7: 378, 8: 261, 9: 182, 10: 1171}\n",
      "------------------  0.6842098424210526 ------------------------\n",
      "exit rate per thresh  {1: 1409, 2: 6333, 3: 5390, 4: 2731, 5: 1644, 6: 908, 7: 306, 8: 229, 9: 137, 10: 912}\n",
      "------------------  0.7368413686842105 ------------------------\n",
      "exit rate per thresh  {1: 1849, 2: 6958, 3: 5335, 4: 2462, 5: 1450, 6: 758, 7: 252, 8: 168, 9: 104, 10: 663}\n",
      "------------------  0.7894728949473684 ------------------------\n",
      "exit rate per thresh  {1: 2459, 2: 7643, 3: 5120, 4: 2169, 5: 1222, 6: 578, 7: 187, 8: 124, 9: 66, 10: 431}\n",
      "------------------  0.8421044212105263 ------------------------\n",
      "exit rate per thresh  {1: 3377, 2: 8219, 3: 4751, 4: 1809, 5: 952, 6: 408, 7: 122, 8: 88, 9: 36, 10: 237}\n",
      "------------------  0.8947359474736842 ------------------------\n",
      "exit rate per thresh  {1: 4908, 2: 8639, 3: 4061, 4: 1318, 5: 615, 6: 226, 7: 67, 8: 50, 9: 16, 10: 99}\n",
      "------------------  0.9473674737368422 ------------------------\n",
      "exit rate per thresh  {1: 7939, 2: 8146, 3: 2797, 4: 741, 5: 244, 6: 86, 7: 21, 8: 9, 9: 4, 10: 12}\n",
      "------------------  0.999999 ------------------------\n",
      "exit rate per thresh  {1: 19934, 2: 65}\n",
      "------------------------------------------------------------------\n",
      "exit rate average  [0.11456823 0.20907045 0.18123656 0.12143107 0.09561478 0.05869543\n",
      " 0.02554128 0.01987599 0.01231312 0.16165308]\n"
     ]
    }
   ],
   "source": [
    "##### passing TRAIN samples through model\n",
    "##### this is to save computation time and exit rates for all the possible branches\n",
    "print(\"%%%%%%%%%%%%%%%%%%%%%%% ResNet20 + cat ans dog(128x128) %%%%%%%%%%%%%%%%%%%%%%%%%%%%\")\n",
    "per_sample_label_list = []\n",
    "per_sample_out_vector_list = []\n",
    "per_sample_comp_latency_backbone_list = []\n",
    "per_sample_comp_latency_exitbranch_list = []\n",
    "\n",
    "\n",
    "#### saving intermediate data once\n",
    "for i in range (len(train_it)):\n",
    "    temp_batch = train_it[i]\n",
    "\n",
    "    for j in range (len(temp_batch[0])):\n",
    "        pic = temp_batch[0][j]\n",
    "        label = temp_batch[1][j]\n",
    "        per_sample_label_list.append(np.array(label).reshape(1,2))\n",
    "\n",
    "        res = model_CIFAR_ResNet(np.array(pic.reshape(1,image_resize,image_resize,3)), training = 1000)\n",
    "   \n",
    "        per_sample_out_vector_list.append(res[0])\n",
    "        per_sample_comp_latency_backbone_list.append(res[1])\n",
    "        per_sample_comp_latency_exitbranch_list.append(res[2])\n",
    "\n",
    "print (\"computation latencies backbone(train data)   \", np.mean(per_sample_comp_latency_backbone_list, axis=0)*1000)\n",
    "print (\"computation latencies exitbranch(train data)   \", np.mean(per_sample_comp_latency_exitbranch_list, axis=0)*1000)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### passing TRAIN samples through model\n",
    "##### this is to save computation time and exit rates for all the possible branches\n",
    "\n",
    "entropy_threshold_list = np.linspace(0.000000001, 0.999999, num=20)\n",
    "\n",
    "### all possible branches, and chosen number\n",
    "chosen_number = branch_number\n",
    "I = list(range(1, branch_number+1))\n",
    "\n",
    "#### number of train samples for simulation\n",
    "sample_number = train_it.samples\n",
    "\n",
    "\n",
    "\n",
    "#### per placement, in this case it is only 1, all the possible branches\n",
    "for item in combinations(I, chosen_number):\n",
    "    placement = list(np.array(item))\n",
    "    print (\"&&&&& selected exit \", placement , \"  &&&&&&\")\n",
    "        \n",
    "    ent_exitrate_list = []\n",
    "\n",
    "    ##### per threshold \n",
    "    for thresh in entropy_threshold_list:\n",
    "        print (\"------------------ \", thresh, \"------------------------\")\n",
    "\n",
    "        threshold_exit = []\n",
    "        threshold_exitrate = [[] for i in range(branch_number)]\n",
    "\n",
    "        ##### per sample\n",
    "        for sample in range (sample_number):\n",
    "\n",
    "            #### determining the exit branch based on entropy of the output and thresh\n",
    "            for exit in range(branch_number):\n",
    "                out = per_sample_out_vector_list[sample][exit]\n",
    "                entropy = -1 * tf.math.reduce_sum((tf.math.log(out) * out)/ np.log(out.shape[1]))\n",
    "\n",
    "                if (entropy < thresh or exit+1==branch_number):\n",
    "                    threshold_exit.append(exit+1)\n",
    "                    break\n",
    "\n",
    "\n",
    "        # handling exit percentage part\n",
    "        unique, counts = np.unique(threshold_exit, return_counts=True)\n",
    "        exitper_list_dict = dict(zip(unique, counts))\n",
    "        print (\"exit rate per thresh \", exitper_list_dict)\n",
    "\n",
    "        for i in range(branch_number):\n",
    "            if (exitper_list_dict.get(placement[i]) is None):\n",
    "                threshold_exitrate[i].append (0)\n",
    "            else:\n",
    "                threshold_exitrate[i].append(exitper_list_dict.get(placement[i]))\n",
    "\n",
    "\n",
    "        ent_exitrate_list.append(np.mean(threshold_exitrate, axis=1)/sample_number)\n",
    "\n",
    "    print(\"------------------------------------------------------------------\")\n",
    "    print(\"exit rate average \", np.mean(ent_exitrate_list, axis=0))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fad9dbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### TEST PART, FOR SIMULATION ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1424344e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computation latencies backbone(test data)    [1.11432074 1.7882254  1.5120326  1.49918471 1.89505629 1.50203495\n",
      " 1.48380924 2.07751615 1.87093451 1.85276709]\n",
      "computation latencies exitbranch(test data)    [0.69392238 0.69457877 0.68776786 0.68741877 0.69685372 0.6818094\n",
      " 0.68248296 0.70836488 0.70242006 0.70320219]\n"
     ]
    }
   ],
   "source": [
    "##### passing TEST samples through model once and save the intermediate data\n",
    "#### this is for doing the simulation\n",
    "\n",
    "per_sample_label_list = []\n",
    "per_sample_out_vector_list = []\n",
    "per_sample_comp_latency_backbone_list = []\n",
    "per_sample_comp_latency_exitbranch_list = []\n",
    "\n",
    "for i in range (len(test_it)):\n",
    "    temp_batch = test_it[i]\n",
    "\n",
    "    for j in range (len(temp_batch[0])):\n",
    "        pic = temp_batch[0][j]\n",
    "        label = temp_batch[1][j]\n",
    "        per_sample_label_list.append(np.array(label).reshape(1,2))\n",
    "\n",
    "        res = model_CIFAR_ResNet(np.array(pic.reshape(1,image_resize,image_resize,3)), training = 1000)\n",
    "   \n",
    "        per_sample_out_vector_list.append(res[0])\n",
    "        per_sample_comp_latency_backbone_list.append(res[1])\n",
    "        per_sample_comp_latency_exitbranch_list.append(res[2])\n",
    "        \n",
    "print (\"computation latencies backbone(test data)   \", np.mean(per_sample_comp_latency_backbone_list, axis=0)*1000)\n",
    "print (\"computation latencies exitbranch(test data)   \", np.mean(per_sample_comp_latency_exitbranch_list, axis=0)*1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21541da1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5549f4d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20ed160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ab3571",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d844c1e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af412dca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cba03a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44967d12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
